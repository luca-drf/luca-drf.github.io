[{"categories":null,"contents":"TL;DR Please stop raising (and in most cases catching) top level Exception in Python.\nThere is basically no good reason for raising Exception in code written for a library, as for catching it, probably the only acceptable case would be in the outermost layer of an application in which no exception should cause the termination of the interpreter (e.g. a Web server) and with the unconditional assumption that the exception is logged somewhere.\nAlso, if you\u0026rsquo;re writing examples for a Python course or guide and your code snippets catch and/or raise Exception please, please, please either state very clearly that in most cases that\u0026rsquo;s an anti-pattern or, you know, use a different exception type üòâ.\nIntroduction I know there are a gazillion blog posts, videos and courses on the Interwebs telling you that catching and/or raising Exception in Python is a no-no. And yet, I\u0026rsquo;ve recently stumbled upon some commercial (and fairly successful) Python library doing it, with predictably terrible results. I won\u0026rsquo;t reveal the name of the library as I don\u0026rsquo;t like to naming and shaming, and I\u0026rsquo;ve already sent some feedback about that their way.\nSo why do experienced Python programmers\u0026rsquo; grumble when they see except Exception in a library? And why do their right eyes start twitching when they see raise Exception?\nThe Case As I was working with a commercial library I ended up having to handle the following exception being raised by the vendor HTTP client (note: I\u0026rsquo;m only reporting the last two formatted lines of the trace stack as the rest is not important):\n... omitted trace stack ... File /my_volume/lib/python3.11/site-packages/vendor/module/utils.py:160, in HTTPUtils.send_request(url, method, token, params, json, verify, auth, data, headers) 158 response.raise_for_status() 159 except Exception as e: --\u0026gt; 160 raise Exception( 161 f\u0026#34;Response content {response.content}, status_code {response.status_code}\u0026#34; 162 ) 163 return response.json() Exception: Response content b\u0026#39;{\u0026#34;error_code\u0026#34;:\u0026#34;NOT_FOUND\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Resource my-resource not found.\u0026#34;,\u0026#34;details\u0026#34;:[{\u0026#34;@type\u0026#34;:\u0026#34;type.googleapis.com/google.rpc.RequestInfo\u0026#34;,\u0026#34;request_id\u0026#34;:\u0026#34;8da16872-3641-43cf-ab6b-3a10559bd6a3\u0026#34;,\u0026#34;serving_data\u0026#34;:\u0026#34;\u0026#34;}]}\u0026#39;, status_code 404 The above is a great example of how NOT to write library code, and if the reason is not clear, please continue reading.\nSo, the above error was thrown when calling the method get_resource() of an instance of said vendor client. The client class basically abstracts a series of common operations on said vendor platform and that under the hood are performed via HTTP requests.\nIn my code I was trying to get a vendor\u0026rsquo;s Resource object and had something like:\nclient = VendorClient() resource = client.get_resource(\u0026#34;my-resource\u0026#34;) As the resource named \u0026ldquo;my-resource\u0026rdquo; was not found, the client threw an exception, and that\u0026rsquo;s okay if it wasn\u0026rsquo;t for the type of such exception which was indeed Exception.\nThat\u0026rsquo;s bad design because Exception being the base class of most of Python\u0026rsquo;s exceptions makes it really hard for the user to handle, unless of course the user is happy to simply catch the exception, probably log it, then either pass or raise. See below:\nclient = VendorClient() try: resource = client.get_resource(\u0026#34;my-resource\u0026#34;) except Exception as e: # At this point we can\u0026#39;t statically infer the type of the error. # If the type was TimeoutError we might wanted to handle it with a retry... # If the type was ValueError we might wanted to add some context to it and re-raise... # But we\u0026#39;ve got Exception instead so statically we can only tell that something # went wrong with client.get_resource() and that\u0026#39;s it. For example, try to write a function that reliably returns True if \u0026ldquo;my-resource\u0026rdquo; exist and False if it doesn\u0026rsquo;t exist using get_resource() (note that VendorClient doesn\u0026rsquo;t implement a \u0026ldquo;resource_exists()\u0026rdquo; method).\nBasically the only thing you can do is somehow parse the error message. I\u0026rsquo;ve asked the vendor to provide an example for the above case and below is what they suggested:\ndef resource_exists(client, resource_name): try: client.get_resource(resource_name) return True except Exception as e: if \u0026#34;NOT_FOUND\u0026#34; in str(e): return False else: raise e Ugh, can you see the problem now? Having to rely on the error message is an extremely brittle solution; error messages are not designed to be interpreted by machines, they\u0026rsquo;re designed for humans! The structure and content of error messages is likely to change as it\u0026rsquo;s not part of the public API of a library. If a vendor library changes the type of an exception raised by a public function they\u0026rsquo;re effectively introducing a breaking change, but changing the error message of a raised exception isn\u0026rsquo;t (and shouldn\u0026rsquo;t be) a change that breaks user\u0026rsquo;s code. Is perfectly okay to not even unit-test complete error messages.\nBut with this vendor\u0026rsquo;s library, error messages are basically public API.\nThe other annoying drawback of calling a function/method that raises Exception is that forces the user to catch Exception hence any other operation in the try block that raises an exception will be caught, forcing the user to have a dedicated try block for get_resource() and be more verbose.\nA better design Let\u0026rsquo;s have another look at the code reported in the error trace stack, see below:\nresponse.raise_for_status() except Exception as e: raise Exception( f\u0026#34;Response content {response.content}, status_code {response.status_code}\u0026#34; ) If you\u0026rsquo;ve used requests library a bit you probably have noticed the raise_for_status() call in the first line, and you probably know that the exception raised is requests.HTTPError which is a very good and feature-rich object (e.g. it contains a reference to the Response objects that raised it for introspection).\nSo why catching it and raising a generic Exception? Also, why catching Exception in the second line when we know that raise_for_status() only raises HTTPError? Who knows ü§∑üèª‚Äç‚ôÇÔ∏è, maybe the code was written by an AI.\nI\u0026rsquo;d fix the above code by removing the except block and let requests.HTTPError propagate. The exception can then be caught at the VendorClient level and wrapped in a custom exception, say NotFoundResource alongside extra VendorClient-specific context.\nFor example:\n# Vendor custom exceptions class ClientError(IOError): def __init__(self, *args, **kwargs): self.request_error = kwargs.pop(\u0026#34;request_error\u0026#34;, None) super().__init__(*args, **kwargs) class NotFoundResource(ClientError): pass # VendorClient.get_resource() def get_resource(name: str, ...): ... try: response = HTTPUtils.send_request(...) except requests.HTTPError as e: if e.response.status_code == 404: raise NotFoundResource(request_error=e) ... Here\u0026rsquo;s how resource_exists() implementation would look like:\ndef resource_exists(client, resource_name): try: client.get_resource(resource_name) return True except NotFoundResource: return False Much nicer don\u0026rsquo;t you think?\nConclusion Catching a specialised exception and then re-raising Exception (the most generic) type, should almost always be avoided. Doing so makes it significantly harder to handle the resulting exception effectively and adds a significant amount of brittleness.\nBefore wrapping code in a try/except block, consider whether that\u0026rsquo;s the right place to handle the exceptions raised by the wrapped code. Remember that sometimes less is more, and it might be better to let the exception propagate to a higher scope.\nWhen handling exception in library code, try to catch explicitly and precisely the type expected, if possible, avoid catching classes that are too generic; the risk being trapping exception unintentionally and ending up with Error Hiding.\nWhen raising an exception, first consider raising a Python built-in exception, and then consider a custom one only if the built-ins are too generic (although they are usually enough).\n","permalink":"https://lucadrf.dev/blog/stop-using-exception/","tags":["python"],"title":"Stop Using Exception"},{"categories":null,"contents":"Introduction In the previous part we explored some practical gotchas that are easily encountered when dealing with floating-point arithmetic. Luckily, IEEE-754 is not the only standard for representing decimal numbers on binary based systems; in the late 80s two standards defining floating-point arithmetic with radices other than 2 (including radix 10) where published IEEE-754-1985 and IEEE-854-1987 and later merged and revised in IEEE-754-2008.\nIBM Mainframe System z9 was the first CPU to implement IEEE-754-2008 in its microcode however most CPUs haven\u0026rsquo;t adopted this standard. On the other hand, this revision is available through software as it has been implemented for most programming languages.\nIn Python, base 10 floating-point arithmetic is implemented in the standard library by the decimal module, and is based on IBM\u0026rsquo;s General Decimal Arithmetic Specification.\nPython\u0026rsquo;s Decimal The decimal module provides support for fast correctly rounded decimal floating-point arithmetic via the Decimal class which presents several advantages over built-in float:\nRepresents decimal numbers exactly, and the exactness carries over into arithmetic Incorporates a notion of significant places as arithmetic operations are defined in base 10 Unlimited precision Exposes all required parts of the standard to the user (precision, rounding strategy, signal handling can all be modified) Decimal objects are immutable (and hashable) Decimal integrates well with other Python‚Äôs built-ins (e.g. round()) The Decimal specification represents fixed and floating-point numbers as triplets consisting of sign (a single bit), digits (an array of unsigned integers) and exponent (a signed integer). For example the number 123.45 is represented as:\n(sign=0, digits=(1, 2, 3, 4, 5), exponent=-2) Python\u0026rsquo;s decimal objects can (and should) be instantiated from strings as using floats would immediately introduce rounding error and noise. For example:\n\u0026gt;\u0026gt;\u0026gt; from decimal import Decimal \u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;0.3\u0026#34;) Decimal(\u0026#39;0.3\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Decimal(0.3) Decimal(\u0026#39;0.299999999999999988897769753748434595763683319091796875\u0026#39;) Note that when instantiating Decimal with float all the digits of the floating-point representation are stored losing precision and obscuring the significance. That defeat the purpose when performing operations:\n\u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;0.3\u0026#34;) + Decimal(\u0026#34;0.3\u0026#34;) Decimal(\u0026#39;0.6\u0026#39;) \u0026gt;\u0026gt;\u0026gt; Decimal(0.3) + Decimal(0.3) Decimal(\u0026#39;0.5999999999999999777955395075\u0026#39;) Taming floating-point arithmetic with decimal In this section we\u0026rsquo;ll see how we can use decimal effectively for solving the problems seen in part 1.\nSolving imprecise addition and subtraction Let\u0026rsquo;s consider non-associative addition as seen in this example; that\u0026rsquo;s not a problem when using decimal\u0026rsquo;s arithmetic as numbers gets aligned to the highest absolute exponent then the sum is carried over in columns (like you would do on a piece of paper). In fact:\n\u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;.9999\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) + Decimal(\u0026#34;.00001\u0026#34;) Decimal(\u0026#39;1.00000\u0026#39;) The result is precise and the resulting Decimal object, stores all the significant figures (the result is 1.00000 not 1). Hurrah!\nTo have look at the decimal tuple stored under the hood, you can use Decimal.as_tuple():\n\u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;1.00000\u0026#34;).as_tuple() DecimalTuple(sign=0, digits=(1, 0), exponent=-5) The same logic is applied to subtraction, therefore solving the floating-point imprecision when subtracting nearly equal numbers seen in example.\nHelping with rounding As mentioned before, Decimal object works well with other built-ins. Here\u0026rsquo;s how rounding invariant works as expected instead of breaking when rounding floats in this example:\n\u0026gt;\u0026gt;\u0026gt; round(round(Decimal(\u0026#34;9.9995\u0026#34;), 3) - round(Decimal(\u0026#34;9.9975\u0026#34;), 3), 3) Decimal(\u0026#39;0.002\u0026#39;) \u0026gt;\u0026gt;\u0026gt; round(round(Decimal(\u0026#34;17.9995\u0026#34;), 3) - round(Decimal(\u0026#34;17.9975\u0026#34;), 3), 3) Decimal(\u0026#39;0.002\u0026#39;) Also, as mentioned before, the decimal module exposes all parts of the standard, for example, the rounding strategy can be modified from the standard \u0026ldquo;Round Half Even\u0026rdquo;. In order to do that you can use Decimal.quantize() method:\n\u0026gt;\u0026gt;\u0026gt; from decimal import ROUND_UP \u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;4.5\u0026#34;).quantize(Decimal(\u0026#34;0\u0026#34;), rounding=ROUND_UP) Decimal(\u0026#39;5\u0026#39;) Decimal\u0026rsquo;s rounding strategies include: ROUND_CEILING, ROUND_DOWN, ROUND_FLOOR, ROUND_HALF_DOWN, ROUND_HALF_EVEN, ROUND_HALF_UP, ROUND_UP, and ROUND_05UP.\nNote that quantize() first argument is a Decimal object, that\u0026rsquo;s to define the exponent (which is extracted from the Decimal instance), personally I wish there was a way to pass the exponent as a number, to be able to write more concise code (or for Decimal to implement a round() method similar to the built-in).\nHelping with significance eater Onto more complex examples, we can rewrite the \u0026ldquo;Significance Eater\u0026rdquo; code seen in example using Decimal to mitigate the behaviour:\ndef significance_eater(): x = Decimal(\u0026#34;10.0\u0026#34;) / Decimal(\u0026#34;9.0\u0026#34;) for _ in range(25): print(x) x = (x - Decimal(\u0026#34;1.0\u0026#34;)) * Decimal(\u0026#34;10.0\u0026#34;) Running the above code\u0026hellip;\n\u0026gt;\u0026gt;\u0026gt; significance_eater() 1.111111111111111111111111111 1.111111111111111111111111110 1.111111111111111111111111100 1.111111111111111111111111000 1.111111111111111111111110000 1.111111111111111111111100000 1.111111111111111111111000000 1.111111111111111111110000000 1.111111111111111111100000000 1.111111111111111111000000000 1.111111111111111110000000000 1.111111111111111100000000000 1.111111111111111000000000000 1.111111111111110000000000000 1.111111111111100000000000000 1.111111111111000000000000000 1.111111111110000000000000000 1.111111111100000000000000000 1.111111111000000000000000000 1.111111110000000000000000000 1.111111100000000000000000000 1.111111000000000000000000000 1.111110000000000000000000000 1.111100000000000000000000000 1.111000000000000000000000000 Note that the loss of significance is still happening due to the finite number of digit stored by Decimal which are defined by decimal module precision setting; however the catastrophic cancellation is a bit more manageable.\nAs mentioned before, decimal precision can be modified by the user, and it\u0026rsquo;s part of decimal Context object which is a singleton instance storing decimal module\u0026rsquo;s settings and events occurred since module import.\nThe Context instance can be accessed via decimal.getcontext() function:\n\u0026gt;\u0026gt;\u0026gt; from decimal import getcontext \u0026gt;\u0026gt;\u0026gt; getcontext() Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999, capitals=1, clamp=0, flags=[], traps=[InvalidOperation, DivisionByZero, Overflow]) To modify the precision, simply:\n\u0026gt;\u0026gt;\u0026gt; getcontext().prec = 64 \u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;10.0\u0026#34;) / Decimal(\u0026#34;9.0\u0026#34;) Decimal(\u0026#39;1.111111111111111111111111111111111111111111111111111111111111111\u0026#39;) \u0026gt;\u0026gt;\u0026gt; getcontext().prec = 30 \u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;10.0\u0026#34;) / Decimal(\u0026#34;9.0\u0026#34;) Decimal(\u0026#39;1.11111111111111111111111111111\u0026#39;) That\u0026rsquo;s nice!\nThe Context object can be used to modify other decimal module settings; the rounding strategy, for instance, can be set to any of the rounding modes available in order to modify the behaviour of all rounding operations performed by the module.\nAnother powerful tool are Signals which can be set as traps in order to raise an exception as soon as an operation triggers one, or can be monitored in the flags list. See Context full docs for more info.\nHelping with Simple Variance Calculator example Let\u0026rsquo;s see how decimal module can fix our \u0026ldquo;Simple Variance Calculator\u0026rdquo; example.\nThe definition of the function was:\nimport numpy as np def simple_variance(nums): sum_of_squares = 0 sum_of_nums = 0 N = len(nums) for num in nums: sum_of_squares += num**2 sum_of_nums += num variance = (sum_of_squares - sum_of_nums**2 / N) / N print(f\u0026#34;Real variance: {np.var(nums)}\u0026#34;) print(f\u0026#34;Simp variance: {variance}\u0026#34;) In this case, we simply pass Decimal objects instead of float\u0026rsquo;s:\n\u0026gt;\u0026gt;\u0026gt; simple_variance([Decimal(str(x)) for x in np.random.uniform(1_000_000, 1_000_000.06, 100_000)]) Real variance: 0.00030060149786485578863919 Simp variance: 0.00030060148 The result is better but not quite there yet. Luckily we can increase the precision to be able to get a more precise result:\n\u0026gt;\u0026gt;\u0026gt; getcontext().prec = 48 \u0026gt;\u0026gt;\u0026gt; simple_variance([Decimal(str(x)) for x in np.random.uniform(1_000_000, 1_000_000.06, 100_000)]) Real variance: 0.000301466911246091199506375296 Simp variance: 0.000301466911246091199506375296 Perfect!\nFraction module Another very interesting tool present in Python\u0026rsquo;s standard library is the fractions module which can greatly help in dealing with operations having inherently rational numbers. Similarly to decimal, fractions implements a Fraction class which can be used to represent rational numbers and implements rational arithmetic.\nFor example, to represent the fraction 11/10 using floats we\u0026rsquo;d use 1.1 but that would result in an approximation:\n\u0026gt;\u0026gt;\u0026gt; from fractions import Fraction \u0026gt;\u0026gt;\u0026gt; Fraction(1.1) Fraction(2476979795053773, 2251799813685248) \u0026gt;\u0026gt;\u0026gt; Fraction(1.1) == Fraction(\u0026#34;11/10\u0026#34;) False With Fraction we can exactly represent 11/10, and we can adjust floats to their nearest rational number with its limit_denominator() method:\n\u0026gt;\u0026gt;\u0026gt; Fraction(1.1).limit_denominator() == Fraction(\u0026#34;11/10\u0026#34;) True \u0026gt;\u0026gt;\u0026gt; from math import pi, cos \u0026gt;\u0026gt;\u0026gt; Fraction(cos(pi/3)) Fraction(4503599627370497, 9007199254740992) \u0026gt;\u0026gt;\u0026gt; Fraction(cos(pi/3)).limit_denominator() Fraction(1, 2) Nice! More examples:\n\u0026gt;\u0026gt;\u0026gt; 0.1 + 0.1 + 0.1 == 0.3 False \u0026gt;\u0026gt;\u0026gt; Fraction(\u0026#34;1/10\u0026#34;) + Fraction(\u0026#34;1/10\u0026#34;) + Fraction(\u0026#34;1/10\u0026#34;) == Fraction(\u0026#34;3/10\u0026#34;) True \u0026gt;\u0026gt;\u0026gt; float(Fraction(\u0026#34;1/10\u0026#34;)) 0.1 \u0026gt;\u0026gt;\u0026gt; float(Fraction(\u0026#34;3/10\u0026#34;)) 0.3 \u0026gt;\u0026gt;\u0026gt; Fraction(Decimal(\u0026#34;1.1\u0026#34;)) Fraction(11, 10) \u0026gt;\u0026gt;\u0026gt; Decimal(\u0026#34;1.1\u0026#34;).as_integer_ratio() (11, 10) Note how Fraction can be used to convert a rational number back to its nearest float, and how a Decimal object represents 1.1 correctly to its ratio 11/10, which can be obtained with Decimal method as_integer_ratio().\nConclusions The decimal module provides support for fast correctly rounded decimal floating-point arithmetic, and it\u0026rsquo;s great for debugging code with complex logic involving floats.\nIn my opinion, overall helps a lot in writing more simple/readable code as it integrates well with other Python‚Äôs built-in as well as other libraries like pandas, although with some performance hit. Note: Arithmetic operations between Decimal and float will raise TypeError.\nBased on simple (by no mean exhaustive) tests, Decimal arithmetic operations seems to be ~70% slower than float, worth noting that CPython uses libmpdec where possible and other implementations of Decimal are available that might be faster (e.g. Apache Arrow pyarrow.decimal128).\nLastly, fractions module is an elegant solution for handling rational numbers, and its limit_denominator() method is very useful.\nThis concludes our two part journey in the vast and perilous world of floating-point arithmetic. Hopefully these posts will help you avoid some of the pitfalls and/or help in troubleshooting them.\n","permalink":"https://lucadrf.dev/blog/taming-floating-points-2/","tags":["python"],"title":"Taming Floating-Point Arithmetic in Python (Part 2)"},{"categories":null,"contents":"Introduction If you\u0026rsquo;re developing software that perform some sorts of numeric calculations, there\u0026rsquo;s a good chance that you\u0026rsquo;ll have to deal with floating-point arithmetic.\nIn this blog post I\u0026rsquo;ll show few practical cases where seemingly innocuous floating-point operations can lead to considerable errors, and how such cases can be treated in Python with the aid of decimal and fractions modules.\nIEEE-754 Double-Precision Floating-Point format The default built-in type used for handling decimal numerals in Python is float which implements IEEE-754 Double-Precision Floating-Point format, and its intrinsic pros and cons.\nDoubles are represented as the result of a multiplication between a fraction (significand) and an exponent and stored in a fixed length binary word of 64 bits (1 bit of sign, 11 bits of signed integer exponent and 52 bits of significand).\nDue to double\u0026rsquo;s format fixed length, real numbers are (in most cases) represented by approximations (i.e. the nearest representable number by a double) For example 0.1, 0.2, 0.3 and 0.4 can\u0026rsquo;t be represented exactly. Also, due to the value of a double being the result of a multiplication, double\u0026rsquo;s values aren\u0026rsquo;t evenly spread across the range or representable numbers.\nFrom Wikipedia:\nBetween 252 (4,503,599,627,370,496) and 253 (9,007,199,254,740,992) the representable numbers are exactly the integers.\nFor the next range, from 253 to 254, everything is multiplied by 2, so the representable numbers are the even ones, etc.\nConversely, for the previous range from 251 to 252, the spacing is 0.5, etc.\nHence, even though the larger absolute value representable with a double is 10308, it makes little sense to use doubles to represent values greater than 252.\nAlthough the magnitude of the above numbers might seem \u0026ldquo;extreme\u0026rdquo; for \u0026ldquo;regular\u0026rdquo; applications, floating-point approximation can create significant problems when performing arithmetic operations with numbers at a much lower scale.\nNote: I haven\u0026rsquo;t mentioned subnormal (or denormal) representation as it\u0026rsquo;s not relevant for the scope of this blog post.\nFloating-Points notable gotchas Addition series are not associative Summing numbers with different orders of magnitude leads to larger approximation errors than numbers of the same order of magnitude, hence changing the order in which multiple sum operations are performed also changes the overall result.\nLet\u0026rsquo;s analise the following examples:\n\u0026gt;\u0026gt;\u0026gt; .9999 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 0.9999999999999996 Note that 1.0 is (obviously) exactly representable with a double, however, the above series of sums returns a double that is close but not exactly 1.0.\nThis is because the Python interpreter executes operators with the same precedence from left to right and the first sum operation that is encountered is .9999 + .00001 which is summing two numbers four order of magnitude apart. The result of this operation is then summed by another .00001, again a sum between two numbers four orders of magnitude apart, and again for the following sums. So, we have a series of ten sums of different magnitudes and that generates enough error that the overall resulting double is close but not quite 1.0.\nSumming the number with the same magnitude first returns a more accurate result. In fact:\n\u0026gt;\u0026gt;\u0026gt; .9999 + (.00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001 + .00001) 1.0 Note that this time we\u0026rsquo;re summing numbers four order of magnitude apart only once.\nThat solves the problem, in this case, but in practice you\u0026rsquo;re much more likely to encounter series of sums as a result of summing in a for loop or when using built-in sum() (or similar third-party implementation) and summing arbitrary iterables (with arbitrary numbers in them and that you don\u0026rsquo;t know much about).\nSo you\u0026rsquo;d have to implement an efficient algorithm to order the numbers by magnitude before summing, which can be a bit of a pain and likely result in a non-trivial performance hit.\nSubtracting nearly equal numbers is not precise Subtractions are also problematic, but unlike additions, problems arise when subtracting numbers very close to each other. For example, imagine you\u0026rsquo;re calculating the distance between two pairs of points on a line:\n\u0026gt;\u0026gt;\u0026gt; 17.9995 - 17.9975 0.0020000000000024443 \u0026gt;\u0026gt;\u0026gt; 9.9995 - 9.9975 0.0019999999999988916 The distance between 17.9995 and 17.9975 and between 9.9995 and 9.9975 should be the same (0.002). However, the results of the two subtractions are close but far enough that if we were to truncate at the third decimal place we\u0026rsquo;d have a result that\u0026rsquo;s half of what it should have been. Or for instance, if we wanted to trigger some kind of behaviour if the distance between two points was \u0026gt; 0.002 then the first pair of points would trigger it, but not the second despite theoretically have the same exact distance.\nIn numerical analysis, this phenomenon is called Catastrophic cancellation.\nAt this point, I can almost hear some of you now laughing at the screen thinking:\n\u0026ldquo;These aren\u0026rsquo;t real issues. Nobody would be fool enough to compare floats that way, compare the rounded numbers instead!\u0026rdquo;\nAnd you would be absolutely right, in this case. But often the code logic is much more complex, and you might find yourself not having a fixed threshold but rather a variable proportion, so you might have to round that number as well and/or you might not know up to how many decimal places is \u0026ldquo;safe\u0026rdquo; to round.\nRounding Rounding can be helpful when comparing or storing decimal numbers, it\u0026rsquo;s always preferable than truncating (unless you want to end up as the Vancouver Stock Exchange) but you should be aware that rounding is an operation that in most cases removes information, hence precision.\nIf we consider the previous section\u0026rsquo;s subtractions, Python\u0026rsquo;s round() can help in quantify the results to the significant digits we need. In fact:\n\u0026gt;\u0026gt;\u0026gt; round(17.9995 - 17.9975, 3) 0.002 \u0026gt;\u0026gt;\u0026gt; round(9.9995 - 9.9975, 3) 0.002 So if rounding the result of the difference to three decimal places returns \u0026ldquo;the expected result\u0026rdquo;, as in my reference system I\u0026rsquo;m always and only interested in three decimal places, surely the invariant would hold if the number were previously rounded to the same number of decimal places. Well, most likely, not:\n\u0026gt;\u0026gt;\u0026gt; round(round(9.9995, 3) - round(9.9975, 3), 3) 0.001 # Hmmmmm.... \u0026gt;\u0026gt;\u0026gt; round(round(17.9995, 3) - round(17.9975, 3), 3) 0.003 # Wait, what?! Surely round(9.9995, 3) == 10.0 and round(9.9975, 3) == 9.998 which differ by 0.002. And surely round(17.9995, 3) == 18.0 and round(17.9975, 3) == 17.998 which also differs by 0.002, right?!\nActually, no. In fact:\n\u0026gt;\u0026gt;\u0026gt; round(9.9995, 3) # 9.9995 is represented by 9.9994999999999993889332472463138401508331298828125 9.999 # Resulting in 9.999 as the fourth decimal place is 4 \u0026gt;\u0026gt;\u0026gt; round(9.9975, 3) # 9.9975 is represented by 9.9975000000000004973799150320701301097869873046875 9.998 # Resulting in 9.998 as the fourth decimal place is 5 \u0026gt;\u0026gt;\u0026gt; 9.999 - 9.998 0.0010000000000012221 # Which rounded is 0.001 Similarly:\n\u0026gt;\u0026gt;\u0026gt; round(17.9995, 3) # 17.9995 is represented by 17.999500000000001165290086646564304828643798828125 18.0 # Resulting in 18.0 as the fourth decimal place is 5 \u0026gt;\u0026gt;\u0026gt; round(17.9975, 3) # 17.9975 is represented by 17.997499999999998721023075631819665431976318359375 17.997 # Resulting in 17.997 as the fourth decimal place is 4 \u0026gt;\u0026gt;\u0026gt; 18.0 - 17.997 0.0030000000000001137 # Which rounded is 0.003 So in the first case the result is half what we expected in the second case is one third more. Not great, considering that we\u0026rsquo;re not dealing with numbers of great magnitude in absolute terms. These are very common magnitudes.\nOn top of the above, is worth remembering that Python\u0026rsquo;s built-in round() implements IEEE-754 default rounding rule, that is \u0026ldquo;Half to Even\u0026rdquo;. Which means that when (and only when) the fractional part of the decimal number is equal to 0.5 then the integer part will be rounded to the nearest even. In fact:\n\u0026gt;\u0026gt;\u0026gt; round(4.5) 4 \u0026gt;\u0026gt;\u0026gt; round(3.5) 4 \u0026gt;\u0026gt; round(4.6) 5 \u0026gt;\u0026gt;\u0026gt; round(0.065, 2) # 0.065 is represented by 0.065000000000000002220446049250313080847263336181640625 0.07 And that\u0026rsquo;s rounding for you.\nMore complex examples All the above examples are interesting but real-life code is much more complex than that. As mentioned, it\u0026rsquo;s much more likely to have to deal with operations executed in series as part of loops or functions, so let\u0026rsquo;s have a look at some more complex (and subtle) examples.\nThe significance eater Consider the following function:\ndef significance_eater(): x = 10.0 / 9.0 for _ in range(25): print(x) x = (x - 1.0) * 10.0 The idea is to show how, due to float\u0026rsquo;s finite representation, significance can be lost \u0026ldquo;gradually\u0026rdquo; by performing a series of operations on the same number.\nNote that we\u0026rsquo;re instantiating x to the value of 10/9 or 1.111\u0026hellip;periodic, then at each iteration of the loop, we first subtract 1 from the number, arithmetically resulting in 0.111\u0026hellip;, then multiply by 10, arithmetically resulting in 1.111\u0026hellip; or the initial number.\nSo if float representation had unlimited memory, at the end of each iteration of the above loop, the value of x would be unchanged. But float is limited to 64bits so what happens when we run the above code is this:\n\u0026gt;\u0026gt;\u0026gt; significance_eater() 1.1111111111111112 1.1111111111111116 1.111111111111116 1.1111111111111605 1.1111111111116045 1.1111111111160454 1.1111111111604544 1.1111111116045436 1.1111111160454357 1.1111111604543567 1.1111116045435665 1.111116045435665 1.11116045435665 1.1116045435665 1.1160454356650007 1.160454356650007 1.6045435665000696 6.045435665000696 50.45435665000696 494.5435665000696 4935.435665000696 49344.35665000696 493433.5665000696 4934325.665000696 49343246.65000696 At each iteration some significance is lost and after the 16th iteration, all the initial information is lost.\nThis behaviour is similar to Overflow and Underflow, but it\u0026rsquo;s harder to spot and troubleshoot.\nSimple variance calculator Consider now the following a na√Øve implementation of a function for calculating the variance of a series of numbers in a single pass:\nimport numpy as np def simple_variance(nums): sum_of_squares = 0 sum_of_nums = 0 N = len(nums) for num in nums: sum_of_squares += num**2 sum_of_nums += num variance = (sum_of_squares - sum_of_nums**2 / N) / N print(f\u0026#34;Real variance: {np.var(nums)}\u0026#34;) print(f\u0026#34;Simp variance: {variance}\u0026#34;) The explanation of the algorithm can be found here.\nNote that the above code prints the variance calculated using the na√Øve approach just after the \u0026ldquo;real\u0026rdquo; variance calculated with a more sophisticated algorithm defined in Numpy, so we can visually compare the two.\nSo if we call simple_variance() passing a list of integers, the algorithm doesn\u0026rsquo;t behave too badly:\n\u0026gt;\u0026gt;\u0026gt; simple_variance([2, 7, 3, 12, 9]) Real variance: 13.84 Simp variance: 13.840000000000003 # not bad But when we pass a very large list of large numbers with little variance, then things gets weird:\n\u0026gt;\u0026gt;\u0026gt; simple_variance(np.random.uniform(1_000_000, 1_000_000.06, 100_000)) Real variance: 0.0003006493219911617 Simp variance: 0.02288 # oh no... \u0026gt;\u0026gt;\u0026gt; simple_variance(np.random.uniform(1_000_000, 1_000_000.06, 100_000)) Real variance: 0.00029977863201331316 Simp variance: -0.00544 # ‰πÅ(‚äô_‚óé)„Ñè In the first call above, the error is two orders of magnitude while in the call we get a negative variance (variance can\u0026rsquo;t be negative)! This is very bad!\nThe problem here is again catastrophic cancellation, and in the above case that happens when subtracting sum_of_squares - sum_of_nums**2 as the sum of squares is very close to the sum of nums squared.\nThe algorithm mentioned above is very well known for its cancellation problem, but I think it\u0026rsquo;s a good example to show how hard it can be to spot these kinds of problems; imagine you had a similar algorithm working relatively fine with certain sets of numbers and then returning \u0026ldquo;garbage\u0026rdquo; when the numbers change!\nConclusions All the above is not only strictly related to Python, any language implementing IEEE-754 Floating-Point arithmetic will have the exact same problems.\nIn the next chapter we\u0026rsquo;re going to see how to tackle all the above problems using only Python\u0026rsquo;s standard library modules.\nReferences If you want to dive deeper into the theory behind the problem exposed in this post, you should definitely start from these links:\nFloating Point Arithmetic: Issues and Limitations The Perils of Floating Point Floating Point Computation, Computer Laboratory, University of Cambridge What Every Computer Scientist Should Know About Floating-Point Arithmetic This blog post was inspired by the following practical guides:\nFP Issues and Limitations Examples of Floating Point problems Losing My Precision: Tips For Handling Tricky Floating Point Arithmetic Well done for getting here, see you soon in the next chapter!\n","permalink":"https://lucadrf.dev/blog/taming-floating-points/","tags":["python"],"title":"Taming Floating-Point Arithmetic in Python (Part 1)"},{"categories":null,"contents":"Rationale Git is a powerful tool that generated an ecosystem of other powerful tools which made developing software in a collaborative environment much, much easier (does anybody remember using CVS?). So it would be a pity to use it only for pushing code on a remote repository when you\u0026rsquo;re done coding for the day.\nI have a feeling that the importance of writing good commits is often overlooked. I\u0026rsquo;ve seen lots of projects with commits messages like Fixed typo, updates or trying something new the latter likely labelling a commit with hundreds of changes. The following are real commit messages from a very successful FOSS library: \\o/, ‚ú®üç∞‚ú®.\nI\u0026rsquo;m always up for a laugh and strongly believe a little dose of silliness can lighten the mood and improve your workday, but my mood wouldn\u0026rsquo;t definitely be uplifted by a cake emoji when I\u0026rsquo;m trying to reconstruct the history of a branch in order to resolve a merge conflict which is blocking the release of a patch our team desperately need. So, please be funny, but also be smart.\nGit commits are more important than most people think and can save you A TON of work if written with common sense. Despite Git itself often being not very intuitive and borderline scary, writing good commits is actually quite easy!\nThe Interwebs are full of blog posts on how to write Git commits and merge/pull requests, but they mostly focus on one single aspect. In this post I\u0026rsquo;ve summarised five simple but fundamental rules that can greatly improve you (and your collaborator) coding life, with minimal effort.\nFive Simple Rules 1. Write atomic commits An atomic Git commit should contain all and only the changes involved in a single unit of work; it doesn\u0026rsquo;t matter if the change is a single character or spans several lines in multiple files, rather it means that you should be able to describe your changes with a single, meaningful message. Moreover, you should be able to revert an atomic commit without any unwanted side effects or regressions, aside from what you‚Äôd expect based on its message. This is crucial when a change needs to be reverted and can save a very long time when troubleshooting problems.\nFurther reading on this topic: aleksandrhovhannisyan.com/blog/atomic-git-commits\n2. Write clear commit messages Commit messages are an invaluable piece of documentation, as they\u0026rsquo;re \u0026ldquo;attached\u0026rdquo; to the code and can be quickly read by most IDEs. Moreover, if well written, they can give unique insight on the evolution of a piece of code, so it\u0026rsquo;s important to include not only what was changed but why was that changed and why changed that way. Also, don\u0026rsquo;t assume who will read the commit message understands what the original problem was, don\u0026rsquo;t assume the code is self-evident/self-documenting and remember that more often than not, commit messages are the only documentation. So, storing any valuable piece of information about the changes in the message is very important!\nCommit messages should be formatted like emails. Think about the first line of the commit message as its subject (try to keep it within 50 columns) and the following lines as the body of the message (try to keep it within 72 columns); leave a blank line between subject and body.\nUse imperative and succinct language for the first line (subject) and then write as many body lines as you need. Bullet points are okay (use hyphens or asterisks) for the bullet followed by a single space.\n50 and 72 columns limits might seem too tight, but considering how much more information is usually displayed alongside a commit message (e.g. git log tree view, blame gutters or simply your favourite IDE\u0026rsquo;s side panel) keeping your messages between those limits makes reading commit messages much easier in virtually all cases. Don\u0026rsquo;t take my word for it, take Tim Pope\u0026rsquo;s.\nGreat (even though a bit hardcore) examples of very well written commit messages can usually be found in the Linux kernel repository.\nMore info on clear commit messages: freecodecamp.org/news/how-to-write-better-git-commit-messages\n3. One merge request per concern Merge requests (or pull requests if you\u0026rsquo;re familiar with GitHub) should cover only one concern (e.g. adding one feature, fixing one bug) and as with atomic commits, reverting them should remove all and only the changes related to that concern. Moreover, strive to keep pull requests \u0026ldquo;small\u0026rdquo; as code reviews quality tends to be inversely proportional to the number of changes to review (i.e. it\u0026rsquo;s likely that reviewers will tend to skim through pull requests with hundreds of changed lines, rather of accurately review all of them).\n10 lines of code = 10 issues.\n500 lines of code = \u0026quot;looks fine.\u0026quot;\nCode reviews.\n\u0026mdash; I Am Devloper (@iamdevloper) November 5, 2013 4. Remember the golden rule of rebasing TL;DR Never rebase onto public branches.\nRebasing is a nice way to keep Git history linear and avoid \u0026ldquo;annoying\u0026rdquo; extra merge commits, but one must keep in mind that rebasing \u0026ldquo;rewrites\u0026rdquo; history. For example, imagine you\u0026rsquo;re working on a branch forked from master, you add some commits to it but then your fork falls behind master. Now you want to pull those changes and rebase your fork on master, so you git pull origin master --rebase, well, this will \u0026ldquo;rewrite\u0026rdquo; your branch history as it will delete your commits from your fork (stashing the changes somewhere), fast-forward adding the commits from origin master, then re-apply your changes as new commits. Your commits will have same changes, commit messages and time stamp, but their hashes will be new. This is totally fine if your fork is local, but, if you pushed your commits to the remote before rebasing, then pushing \u0026ldquo;re-written\u0026rdquo; commits will fail. At this point you could force-push or do another merge/rebase, but in any case merging your forked branch back to master will duplicate commits. Also, at this point, if someone else pulled your forked branch before you \u0026ldquo;rewriting\u0026rdquo; it, will have a diverging tip and get very confused when trying to pull/push again. Moreover, upon merging the fork back onto master, \u0026ldquo;rewritten\u0026rdquo; commits will end up as duplicated. In order to avoid all the above, is good practice to rebase only local branches (branches that haven\u0026rsquo;t been pushed onto a remote).\nMore info: atlassian.com/git/tutorials/merging-vs-rebasing#the-golden-rule-of-rebasing\n5. Pull frequently to minimize merge conflicts and derived bugs Pulling new changes off upstream daily, reduces the chances of ending up with annoying (and potentially painful to fix) merge conflicts when opening a merge/pull request. Resolving merge conflicts can be a very delicate matter and even when the code is well understood the chances to introduce bugs are very high.\n","permalink":"https://lucadrf.dev/blog/git-etiquette/","tags":["git"],"title":"Git Etiquette"},{"categories":null,"contents":"TL;DR See this gist\nProblem Most of Microsoft Azure\u0026rsquo;s Python packages have uAMQP (azure-uamqp-python) as a dependency, hence if you\u0026rsquo;re developing any automation involving Azure with Python, you\u0026rsquo;d almost certainly need to install it in your pipeline. Under the hood, Python uAMQP uses its C counterpart azure-uamqp-c as an extension, therefore that\u0026rsquo;s required as an appropriate byte-compiled library for the target architecture, system and Python version the pipeline is running on.\nIn most cases, third-party Python packages that requires C extensions are shipped in archives where the Python code is packaged alongside the compiled extensions. Such archives are called wheels and can be installed as any other third-party package, using Pip, given that pre-built wheels targeting architecture, system and Python version Pip is installing on, are provided and available on the PyPI repository for the package.\nMicrosoft is publishing uAMQP Python wheels targeting Windows, Linux and MacOS, and for all live major Python 3 versions (3.7+). The only problem is that the only targeted architecture is x86_64 (see last uAMQP release on PyPI).\nTo be fair the source code is well engineered and can be fairly easily compiled for Linux on Arm architectures, in fact uAMQP GitHub repo, features build scripts for Python 3.5 on armV7 (which could probably work on a Raspberry PI 2 see here) but the Manylinux one is strictly targeting x86_64.\nSo as arm64v8 based servers are becoming widely adopted by public Cloud providers, I find quite peculiar the lack of arm64 pre-built wheels on PyPI. It\u0026rsquo;s definitely not a technical challenge/burden for uAMQP maintainers (I think), and I hope they\u0026rsquo;ll start providing them, and so are other devs on azure-uamqp-python\u0026rsquo;s Issues on GitHub.\nDon\u0026rsquo;t get me wrong, I\u0026rsquo;m really glad the direction Microsoft took in the last decade, heavily investing on Open Source and Python. Kudos to them!\nA solution So in the meantime, if you need to build uAMQP for your Linux system running on Arm, below is a build script that should do the trick. It requires docker and an image provided by the amazing Manylinux project.\nCross compile aarch64 on x86_64 Note that you can use the same script to cross compile for aarch64 on a Linux x86_64 machine, thanks to the very clever qemu-user-static docker image by simply running the following container before the above script:\ndocker run --rm --privileged multiarch/qemu-user-static --reset -p yes I\u0026rsquo;m not going to go into details on how the above works as it\u0026rsquo;s a bit out of the scope of this post, but I strongly recommend to everyone reading about it as what they did is a beautiful hack and, in my opinion, shows why running containers in privileged mode can be both powerful and extremely dangerous at the same time.\n","permalink":"https://lucadrf.dev/blog/uamqp-manylinux-arm64/","tags":["python","arm","manylinux","microsoft","azure"],"title":"Build uAMQP Python wheel for arm64v8"},{"categories":null,"contents":"TL;DR Here\u0026rsquo;s how to read and print a subprocess stdout in \u0026ldquo;real-time\u0026rdquo;, or in other words, capture the subprocess\u0026rsquo; stdout as soon as bytes are written to it.\n# parent_process.py from subprocess import Popen, PIPE with Popen([\u0026#34;python\u0026#34;, \u0026#34;child_process.py\u0026#34;], stdout=PIPE) as p: while True: # Use read1() instead of read() or Popen.communicate() as both blocks until EOF # https://docs.python.org/3/library/io.html#io.BufferedIOBase.read1 text = p.stdout.read1().decode(\u0026#34;utf-8\u0026#34;) print(text, end=\u0026#39;\u0026#39;, flush=True) # child_process.py from time import sleep while True: # Make sure stdout writes are flushed to the stream print(\u0026#34;Spam!\u0026#34;, end=\u0026#39; \u0026#39;, flush=True) # Sleep to simulate some other work sleep(1) If you\u0026rsquo;d like to learn more about Python\u0026rsquo;s I/O, buffers configuration, and a real life problem that inspired this blog post, keep reading :)\nProblem On a Python group chat I\u0026rsquo;ve read an interesting question, I\u0026rsquo;m reporting an edited version below:\nI have a script that opens a program with Popen. stdout is redirected to a PIPE. The script reads few lines on stdout to discover how to connect to the program using a socket. Unfortunately, at some point later the stdout pipe gets full as it isn\u0026rsquo;t read, and it blocks the subprocess.\nThat behaviour is expected, in fact, it\u0026rsquo;s mentioned in Python\u0026rsquo;s subprocess docs for Popen.wait()\nThis will deadlock when using stdout=PIPE or stderr=PIPE and the child process generates enough output to a pipe such that it blocks waiting for the OS pipe buffer to accept more data.\n(Note: I have omitted the last sentence about Popen.communicate() as it\u0026rsquo;s not relevant for our case, I\u0026rsquo;ll go back to it in more detail later.)\nSo, how can we read the first few lines written by a subprocess on its stdout, save them and throw away the rest while the subprocess is running and writing without stopping it?\nTL;DR (part 2), take me to the solution\nA solution Using a text file instead of a pipe We could redirect our subprocess stdout to a file instead of a pipe, read the first few lines and forget about the rest until the subprocess terminate and then delete the file.\nThat would possibly look something like this:\nfrom subprocess import Popen from time import sleep max_lines_to_read = 10 lines_read = 0 with open(\u0026#34;my_command.out\u0026#34;, \u0026#34;w\u0026#34;) as subprocess_out: with Popen([\u0026#34;my_command\u0026#34;], stdout=subprocess_out) as process: with open(\u0026#34;my_command.out\u0026#34;, \u0026#34;r\u0026#34;) as subprocess_in: while True: text = subprocess_in.read() if not text: sleep(1) continue if lines_read \u0026lt; max_lines_to_read: if text.endswith(\u0026#34;\\n\u0026#34;): # TODO: Store or use the whole line lines_read += 1 else: break # TODO: Write the rest of the logic here and terminate `process` if needed Note: I didn\u0026rsquo;t use readline() or readlines() because they would behave just like read() if our subprocess doesn\u0026rsquo;t terminate each write with a new line (i.e. use one write per line) so it\u0026rsquo;s less confusing to simply use read() and look for \\n ourselves.\nThis solution works, but if we\u0026rsquo;re only interested in few lines there\u0026rsquo;s really no point in having that file on disk, what if it ends up being several gigabytes and the subprocess having to run for days? You don\u0026rsquo;t want to be that person who forced IT to impose stricter quotas on your VMs mounts, do you? üòâ\nNo, we\u0026rsquo;re dealing with a stream of data, and we should be coding accordingly.\nSo, how can we stream the output of a subprocess as it gets generated, rather than waiting for it to terminate and print it all?\nWhat does the official Python documentation suggests? If we read Python\u0026rsquo;s official documentation (as all good Pythonistas always do) for subprocess module, we\u0026rsquo;re strongly encouraged to use Popen.communicate() for writing/reading piped subprocesses STDIN/STDOUT. That doesn\u0026rsquo;t quite work the way we expect though, in fact communicate() seems to be blocking and even calling it with a timeout communicate(timeout=2) doesn\u0026rsquo;t seem to work as bytes aren\u0026rsquo;t returned while the pipe is open and being written. Bummer.\nUnfortunately Python\u0026rsquo;s official documentation doesn\u0026rsquo;t offer any alternative solution, \u0026ldquo;There should be one \u0026ndash; and preferably only one \u0026ndash; obvious way to do it.\u0026rdquo; the Zen of Python says, although using Popen.communicate() to read the stdout of a piped subprocess is all but obvious. Sorry Zen of Python and official docs, but we have to find another way.\nPython buffers and I/O While trying to figure out why Popen.communicate() didn\u0026rsquo;t work as expected I\u0026rsquo;ve refreshed my knowledge on POSIX pipes and buffering strategies in libc. There are essentially three kinds of streams:\nUnbuffered (characters are transmitted individually, as soon as possible) Line buffered (characters are transmitted in blocks, when new line is encountered) Fully buffered (characters are transmitted in blocks of arbitrary size) See GNU Buffering Concepts.\nTypically, POSIX pipes are fully buffered streams, while streams attached to a TTY are usually line buffered. It\u0026rsquo;s important to remember that, especially when redirecting stdout to a pipe or a file (instead of a terminal).\nPython follows the same strategies when implementing its buffers, and it\u0026rsquo;s also worth remembering that an extra layer of internal buffering might occur on both reads and writes.\nLastly, it\u0026rsquo;s important to remember that stdout streams in Python can be handled by different io classes, depending on the type of stream/buffering strategy.\nLine buffered streams (TTY) Consider the following program, I\u0026rsquo;ve called it spam_one_line.py:\n# spam_one_line.py import sys from time import sleep for _ in range(8): print(\u0026#34;Spam!\u0026#34;, end=\u0026#39; \u0026#39;) # Printed string ends with a space instead of the default sleep(1) print(\u0026#34;Lovely Spam! Wonderful Spam!\u0026#34;) print(\u0026#34;Line written\u0026#34;, file=sys.stderr) What do you think the output of this program will be on your terminal? Or more importantly, when do you think those characters will appear?\nSpoiler alert: two lines will appear at the same time:\nSpam! Spam! Spam! Spam! Spam! Spam! Spam! Spam! Lovely Spam! Wonderful Spam! Line written That\u0026rsquo;s because stdout and stderr are both attached to a TTY and that by default means sys.stdout and sys.stderr are instances of io.TextIOWrapper (which is the same type of instance that is returned by open() when opening a text file) but with line_buffering=True. Hence, characters are flushed onto the underlying binary buffer when new line is encountered.\nIt\u0026rsquo;s easy to check whether a stream is attached to a TTY as io.IOBase class implements isatty() method that can be invoked on all its subclasses; in this case sys.stdout.isatty() == True.\nSo what if we want to \u0026ldquo;print immediately\u0026rdquo; on stdout? Well, one way to do it is to call print() with flush=True:\nprint(\u0026#34;Spam!\u0026#34;, end=\u0026#39; \u0026#39;, flush=True) From Python 3.7 onwards, another way is to reconfigure sys.stdout to disable the interpreter\u0026rsquo;s buffer and transmit all the subsequent writes to the system buffer:\nsys.stdout.reconfigure(write_through=True) Fully buffered streams (pipe) What buffering strategy and what type of stream is Python implementing when a Python process is invoked using subprocess.Popen and its stdout is redirected to a pipe instead of being attached to a TTY?\nLet\u0026rsquo;s first refresh what a pipe is and how it works:\nIn very simple terms, a pipe is a mechanism for multiprocess communication provided by the OS. It has two separate ends, a writing and a reading one. The data is handled in a first-in, first-out (FIFO) order.\nSo when we call subprocess.Popen and redirect the subprocess\u0026rsquo; stdout to a pipe, Popen first creates the pipe, which means creating the two ends as two separate binary file descriptors pointing to the same file (one in reading mode and one in writing mode); then forks the calling process (creating a child process which will share both file descriptors), redirect the child process stdout to the file descriptor pointing at the writing end of the pipe, and finally exec the program that should run as the child process.\nFor more info see libc\u0026rsquo;s Pipes and FIFOs, Creating a pipe and Pipe atomicity documentation.\nSo for example if we instantiate a process object as:\nwith subprocess.Popen([\u0026#34;my_command\u0026#34;], stdout=subprocess.PIPE) as process: ... Then process.stdout will hold the reading end of the pipe while (assuming \u0026ldquo;my_command\u0026rdquo; is another Python program) the child process\u0026rsquo; sys.stdout will hold the writing end.\nIt\u0026rsquo;s important to notice that the reading end is handled by an instance of io.BufferedReader as it\u0026rsquo;s open in binary reading mode while the writing end will still be handled by an instance of io.TextIOWrapper (again, assuming the child process runs a Python program) but in this case both sys.stdout.isatty() and sys.stdout.line_buffering will evaluate to False.\nConfiguring a subprocess piped STDOUT Okay, so, using a io.BufferedReader instance in our use case isn\u0026rsquo;t great, because we basically want to read lines from stdout as if it was attached to a TTY. So, is there a way to reconfigure our piped subprocess stdout buffering strategy? Luckily, this time, the answer can be found by reading Popen docs and its many, many options; in fact, setting bufsize=1 and universal_newlines=True when invoking Popen, will change the reading end of our pipe\u0026rsquo;s type to io.TextIOWrapper and the underlying buffer will be line buffered. Note that the wrapper\u0026rsquo;s buffer on top of the binary one, instead, will have line_buffering=False (which is a bit confusing but coherent).\nSo, having io.TextIOWrapper instead of io.BufferedReader as our reading end, make Popen.communicate() non-blocking and behave as we expect? Sadly, no. But, we can read directly from the stdout stream of our subprocess, remember? And since our reading end (process.stdout) is an instance of io.TextIOWrapper and the buffering strategy is line buffered we can call readline() on it and expect it to block until a full line is available on the buffer and return it.\nSo now we should have all what we need to solve our initial problem in a better way.\nAnother (but better) solution Instead of dumping our subprocess output to a file, reading the first few lines and forgetting about the following ones; we could consume the subprocess\u0026rsquo; output in a separate thread, send the first few lines to the parent process using a queue and then continue to consume the rest of the output in the thread (and discarding it). This way we\u0026rsquo;d use only the memory we need.\nfrom subprocess import Popen, PIPE from threading import Thread from queue import SimpleQueue def consume_output(p, q, max_lines): line_count = 0 while p.poll() is None: line = p.stdout.readline() if line_count \u0026lt; max_lines: q.put(line) line_count += 1 def main(max_lines): program_output = [] line_count = 0 with Popen([\u0026#34;my_command\u0026#34;], stdout=PIPE, bufsize=1, universal_newlines=True) as p: q = SimpleQueue() t = Thread(target=consume_output, args=(p, q, max_lines)) t.start() while True: line = q.get() program_output.append(line) line_count += 1 if line_count == max_lines: break # TODO: Write the rest of the logic here and do what you need with `program_output` p.terminate() t.join() # Blocks until t terminates if __name__ == \u0026#34;__main__\u0026#34;: main(max_lines=2) Note: we\u0026rsquo;re using Popen.poll() to check whether the child process is running or has terminated, in case it has been terminated, the thread shall also terminate.\nAlso note that if \u0026ldquo;my_command\u0026rdquo; is a Python program as well, you\u0026rsquo;ll have to remember to flush prints that you want to transmit immediately, because since sys.stdout has been redirected to a pipe then sys.stdout.line_buffering == False and the buffer will be flushed only when the underlying binary buffer is full.\n# spam_many_lines.py import sys from time import sleep while True: for _ in range(8): print(\u0026#34;Spam!\u0026#34;, end=\u0026#39; \u0026#39;, flush=True) sleep(1) print(\u0026#34;Lovely Spam! Wonderful Spam!\u0026#34;, flush=True) print(\u0026#34;Line written\u0026#34;, file=sys.stderr) Problem solved.\nThat\u0026rsquo;s great, but the title of this blog post mentions capturing output in \u0026ldquo;real time\u0026rdquo;; so what if the child process doesn\u0026rsquo;t atomically writes full lines? For example, what if we want to capture the output of one of those command line programs that print their progress on one line (e.g. with a progress-bar)? In that case reading line-by-line wouldn\u0026rsquo;t be of much use.\nReal-Time output In an earlier section, we talked about our subprocess piped stdout being handled by a io.BufferedReader instance; that is the default mode subprocess.Popen instantiates our process.stdout.\nBy default, io.BufferedReader, handles a fully buffered, binary stream, and implements a read() method, although that blocks until EOF if called with a negative o no parameter, otherwise if called with a positive integer n will block until n bytes are read.\nI must say, io.BufferedReader.read() behaviour is not very clear from the official Python documentation in my opinion especially because other read methods like io.TextIOWrapper.read() or os.read() return \u0026ldquo;up to\u0026rdquo; n bytes when called with a positive integer, which means they won\u0026rsquo;t block.\nSo, is there a way to read bytes from a binary buffer as soon as they\u0026rsquo;re written, without having to wait for EOF (hence before the writing process closes the pipe), and without having to read byte by byte with read(1) (which is not very efficient)?\nLuckily, that can be achieved by using a different read method: io.BufferedReader.read1() (even though, again, the official Python documentation is not super clear).\nAnother option would be calling os.read() passing the subprocess\u0026rsquo; stdout file descriptor and a positive n in order to read at most n bytes per call.\nLet\u0026rsquo;s write a simple program that just reads the subprocess stdout and prints it in real-time:\nimport sys from subprocess import Popen, PIPE with Popen([\u0026#34;my_command\u0026#34;], stdout=PIPE) as p: while True: text = p.stdout.read1().decode(\u0026#34;utf-8\u0026#34;) print(text, end=\u0026#39;\u0026#39;, flush=True) # TODO: Write the rest of the logic here and terminate `process` if needed That\u0026rsquo;s it!\nNote that, alternatively, you could have also used os.read() in case you wanted to read up to a fixed number of bytes, so you could have rewritten the read line as:\ntext = os.read(p.stdout.fileno(), 1024).decode(\u0026#34;utf-8\u0026#34;) (Obviously you\u0026rsquo;d have to import os for that)\nMore on Python buffers The default buffer size of all concrete io.Buffered* classes is io.DEFAULT_BUFFER_SIZE which is platform dependant.\nIn case you wanted to change buffer strategy for stdout stream, you can re-initialise it. For example, in the above spam_many_lines.py you might want to set custom buffer settings in case stdout is not attached to a TTY, but keep default settings otherwise (and/or not want to pass flush=True to all print() functions).\nSo you could first check if sys.stdout is attached to a TTY, then disable io.TextIOWrapper buffer and instead set a custom buffer size for the underlying binary buffer.\nif not sys.stdout.isatty(): buff_size = 8 sys.stdout = io.TextIOWrapper( open(sys.stdout.fileno(), \u0026#39;wb\u0026#39;, buff_size), write_through=True, encoding=\u0026#34;utf-8\u0026#34; ) Note, stdout buffer will be automatically flushed after 8 bytes have been written.\nAnd that\u0026rsquo;s all I\u0026rsquo;ve got on Python buffers for now.\nIf you made it here, give yourself a pat on the back and see you soon!\n","permalink":"https://lucadrf.dev/blog/python-subprocess-buffers/","tags":["python","subprocess","unix"],"title":"Capture Python subprocess output in real-time"},{"categories":null,"contents":"As a Web back-end developer, in general, I\u0026rsquo;ve been quite happy working on an Apple M1 platform. AArch64 is fairly well-supported and Rosetta2 fills most of the gaps left open by the lack of available ARM64 builds.\nAn example of missing support for darwin/arm64 are Oracle Instant Client libs. Luckily there are neat ways around it üôÇ\nProblem Recently I wrote a Python program to extract some data from an \u0026ldquo;old\u0026rdquo; Oracle DB 11.2. Oracle provides a nice Python library to talk with Oracle DB which was recently updated and renamed oracledb. The only problem is that Oracle DB 11.2 is only supported in Thick mode which requires Oracle Instant Client libraries.\nAt the time of writing, Oracle doesn\u0026rsquo;t distribute Oracle Instant Client arm64 builds for macOS and doesn\u0026rsquo;t seem to be planning to. So I wondered how difficult would have been to manage x86 libraries and executables alongside native arm64 ones in order to keep most of my development setup and workflows (i.e. avoiding having to install VMs for developing with x86 libs and x86 Python builds).\nAfter doing some research on the Interwebs, I found two or three solutions that worked, but all of them involved some hackish setup. In the following guide I\u0026rsquo;ll show my approach in which I tried to be as neat and safe as possible.\n(I\u0026rsquo;m assuming XCode and Command Line Tools are already installed on your System)\nHere we go:\nRosetta2 A good way to run darwin/x86_64 software on Apple Silicon is using Rosetta2 which is very well integrated in macOS and can be installed by simply:\n/usr/sbin/softwareupdate --install-rosetta --agree-to-license You might get a Package Authoring Error message, but that shouldn\u0026rsquo;t prevent the installation to terminate successfully.\nx86 Terminal The Terminal (in my case iTerm2) is my main entry point for running software when developing, so with Rosetta2 installed I first need an x86 emulated Terminal. That can be achieved by simply \u0026ldquo;right-clicking\u0026rdquo; on iTerm2 app, \u0026ldquo;Duplicate\u0026rdquo; it, rename the copied version \u0026ldquo;iTerm-x86\u0026rdquo;, then select it and open the info panel (‚åò-I), and finally select \u0026ldquo;Open Using Rosetta\u0026rdquo; checkbox. Done. Note that the same can be done with any other macOS app.\nIt\u0026rsquo;s probably a good idea to update your command prompt to display some kind of info about the architecture in order not to get confused when you have two terminals looking exactly the same but running two different environments.\nI\u0026rsquo;ve added the following code to my zsh theme and included the variable in my prompt.\nif [ $(arch) = \u0026#34;i386\u0026#34; ]; then ARCH_PROMPT=\u0026#34;x86\u0026#34; else ARCH_PROMPT=\u0026#34;arm\u0026#34; fi Note: you can always launch an x86 shell within your current shell:\narch -x86_64 zsh Also note: the environment will be inherited in the new shell session. Personally I find it safer to keep two separated terminals.\nx86 Homebrew Mac Homebrew comes very handy for building and managing OSS on macOS. Since Mac Homebrew on arm64 is rooted at /opt/homebrew instead of /usr/local, it\u0026rsquo;s possible to install x86 software and keep it neatly separated from arm64. You just need to launch an x86 shell and simply install Mac Homebrew. It will automatically choose its root based on the detected architecture (in our case i386).\nThen, in order to make sure your environment is properly set, add the following code to your .zprofile (or .profile):\nif [ $(arch) = \u0026#34;i386\u0026#34; ]; then eval \u0026#34;$(/usr/local/bin/brew shellenv)\u0026#34; else eval \u0026#34;$(/opt/homebrew/bin/brew shellenv)\u0026#34; fi x86 Python with Pyenv Now that we have an x86 terminal and a dedicated space for our x86 libraries, we need to build an x86 CPython interpreter. Luckily Pyenv will sort that out for us.\nPyenv In order to build Python, we\u0026rsquo;re going to use Pyenv (which you should be using already for managing different Python versions and virtualenvs anyway). Don\u0026rsquo;t worry if you already installed an \u0026ldquo;arm\u0026rdquo; Pyenv, and have already populated Pyenv\u0026rsquo;s root; the two executables won\u0026rsquo;t interfere with each other as they can share the same root (e.g. ~/.pyenv).\nSo using our x86 terminal, let\u0026rsquo;s install Pyenv in the x86 space:\nbrew install pyenv pyenv-virtualenv Note: you might need to reload the shell in order for pyenv-virtualenv to work. Also note: brew will take care of openssl and readline dependencies installing their x86 versions in /usr/local/opt.\nLet\u0026rsquo;s also install Pyenv Alias a handy Pyenv plugin for labelling Python versions, so we can keep arm and x86 Python builds separated under $(pyenv root)/versions:\ngit clone https://github.com/s1341/pyenv-alias.git $(pyenv root)/plugins/pyenv-alias Python Now we can build an x86 Python interpreter using our x86 terminal and Pyenv. Also, let\u0026rsquo;s give it a custom name, so it won\u0026rsquo;t interfere with other arm versions:\nVERSION_ALIAS=\u0026#34;3.10.3_x86\u0026#34; pyenv install 3.10.3 If everything worked fine, you should be able to run a Python REPL and check the interpreter platform using the platform module:\n\u0026gt;\u0026gt;\u0026gt; import platform \u0026gt;\u0026gt;\u0026gt; platform.machine() \u0026#39;x86_64\u0026#39; \u0026gt;\u0026gt;\u0026gt; Note that even when using an x86 terminal, an arm built Python interpreter would print 'arm64'.\nOracle Instant Client \u0026amp; Python Finally, we have all that we need to install Oracle Instant Client, and calling it from Python.\nSo, using our x86 terminal, let\u0026rsquo;s install Oracle Instant Client libraries with brew. We\u0026rsquo;ll need to add a new tap first:\nbrew tap InstantClientTap/instantclient Then we can install the required libs (in my case, I only needed the basic-lite version):\nbrew install instantclient-basiclite At the time of writing, the above command should install Instant Client Basic Lite version 19.8.0.0.0.\nLet\u0026rsquo;s now create a virtualenv for our project:\npyenv virtualenv 3.10.3_x86 oracle_client_app And activate it:\npyenv activate oracle_client_app Let\u0026rsquo;s install the new python-oracledb which has replaced cx_Oracle (although the latter would work as well):\npip install oracledb Then test that Instant Client is correctly loaded. To do that, open a python REPL and then:\n\u0026gt;\u0026gt;\u0026gt; import oracledb \u0026gt;\u0026gt;\u0026gt; oracledb.init_oracle_client() \u0026gt;\u0026gt;\u0026gt; oracledb.clientversion() (19, 8, 0, 0, 0) \u0026gt;\u0026gt;\u0026gt; Nice, now we can start developing our app!\nDocker As the app I was developing was going to be deployed as a Docker container, I also wondered if there was an easy way to build an x86 Docker image on my M1 Mac; and perhaps, spin up an x86 container as well, so I could \u0026ldquo;smoke test it\u0026rdquo; locally.\nThe answer is, well, in this case yes!\nPython Toy App For the purpose of this guide the app will simply init Oracle Client and then print its version on stdout.\n# oracle_client_app.py import oracledb oracledb.init_oracle_client() version = oracledb.clientversion() print(f\u0026#34;Oracle Client version: {version[0]}.{version[1]}.{version[2]}\u0026#34;) Dockerfile Now we need a Dockerfile that installs all our dependencies:\nFROM python:3.10.3-slim-buster # Install Oracle Instant Client WORKDIR /opt/oracle RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y libaio1 wget unzip \\ \u0026amp;\u0026amp; wget https://download.oracle.com/otn_software/linux/instantclient/1915000/instantclient-basiclite-linux.x64-19.15.0.0.0dbru-2.zip \\ \u0026amp;\u0026amp; unzip instantclient-basiclite-linux.x64-19.15.0.0.0dbru-2.zip \\ \u0026amp;\u0026amp; rm -f instantclient-basiclite-linux.x64-19.15.0.0.0dbru-2.zip \\ \u0026amp;\u0026amp; cd /opt/oracle/instantclient_19_15 \\ \u0026amp;\u0026amp; rm -f *jdbc* *occi* *mysql* *README *jar uidrvci genezi adrci \\ \u0026amp;\u0026amp; echo /opt/oracle/instantclient_19_15 \u0026gt; /etc/ld.so.conf.d/oracle-instantclient.conf \\ \u0026amp;\u0026amp; ldconfig \\ \u0026amp;\u0026amp; apt-get purge -y --auto-remove wget unzip WORKDIR /app COPY oracle_client_app.py /app # Install GCC for compiling python-oracledb and then install it RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y gcc \\ \u0026amp;\u0026amp; apt-get clean \\ \u0026amp;\u0026amp; pip install --no-cache-dir oracledb \\ \u0026amp;\u0026amp; apt-get purge -y --auto-remove gcc CMD [\u0026#34;python\u0026#34;, \u0026#34;oracle_client_app.py\u0026#34;] Note: at the time of writing, the latest Oracle Client version for Linux64 is 21.6.0\nBuild and Run We can build our x86 image by using Docker\u0026rsquo;s --platform parameter:\ndocker build --platform linux/amd64 -t oracle_client_app And then run it using the same parameter:\ndocker run --platform linux/amd64 oracle_client_app:latest Which, if everything went well, should print:\nOracle Client version: 19.15.0 Et voil√†! üíÅüèª‚Äç‚ôÇÔ∏è\nConclusion This neat solution wouldn\u0026rsquo;t have been possible without Mac Homebrew maintainers separating x86 installations from arm ones, kudos to them.\nMassive kudos to Apple for Rosetta2 and XCode working seamlessly in emulation mode.\nAnd last but not least, it\u0026rsquo;s really nice to see Docker Desktop for macOS emulating x86 out of the box on Apple Silicon.\nHappy coding!\n","permalink":"https://lucadrf.dev/blog/oracle-python-m1/","tags":["python","oracle","arm","apple m1","docker"],"title":"Oracle Client and Python on Apple Silicon"},{"categories":null,"contents":"HUGO is really fast when it comes to building static assets, but its real speed is its linear learning curve.\nBackground I was looking to build a personal website that I could easily update and deploy. I\u0026rsquo;ve used WordPress in the past, but this time I wanted to try something simpler (didn\u0026rsquo;t really need any server-side capabilities). As I\u0026rsquo;m not really a Web front-end developer, and I\u0026rsquo;m not massively interested in diving into UI/UX too deep, my main focus is on content editing and deployment automation.\nBasically I just wanted to be able to write a bunch of Markdown (or similar markup language), compile it into nice HTML (with maybe a little client-side JS code to improve the UX), test it locally (my development platform is an Apple Silicon Mac) then version and deploy it with as little hassle as possible.\nLuckily for me, all the above requirements are covered by a framework called HUGO which is a static website generator written in Go (having basic knowledge of Go helps but isn\u0026rsquo;t really required for effectively use HUGO).\nThe main advantage of maintaining/deploying a static website is that it only requires a CDN to be served (with obvious advantages also in terms of security/privacy and testing), so in this case I\u0026rsquo;m hosting this site using GitHub Pages which provides the CDN and all the CI/CD tools I need in one place.\nDevelopment First I\u0026rsquo;ve installed HUGO I\u0026rsquo;m developing on an Apple Silicon Mac, and HUGO can be easily installed via Mac Homebrew with:\nbrew install hugo Then I created a new site:\nhugo new site lucadrf.dev At this point I needed a base theme, as I didn\u0026rsquo;t want to build the whole site from scratch (and had zero experience with HUGO). There are hundreds of themes to chose from that span several use cases. In my case I wanted mainly a \u0026ldquo;resume style\u0026rdquo; home page with maybe a blog space. I\u0026rsquo;ve found just what I was looking for with this theme which code was conveniently hosted on GitHub as well (thank you eddiewebb).\nAs I wanted to add several changes to the theme I figured it would have been cleaner to fork it and maintain my own (simplified) version. So I did it and added my own fork to the project as a submodule:\ncd lucadrf.dev git init git submodule add https://github.com/luca-drf/hugo-resume.git themes/hugo-resume Using exampleSite as reference I\u0026rsquo;ve added my:\ndata/skills.json data/experience.json data/education.json Then updated config.toml and finally built the site with:\nhugo The entire website will be compiled and stored in ./public (default) as static assets.\nA really nice feature is the development web server which serves the site locally and can be configured to rebuild/reload upon changes. To run the server I\u0026rsquo;ve simply:\nhugo server More info about setting up HUGO and the theme at:\nHUGO Quickstart Hugo Resume Deployment After several iterations of coding and local testing, and having obtained a decent site, I\u0026rsquo;ve set up automated deploy on GitHub Pages, taking advantage of GitHub Actions and its community. In fact there are already two repositories with a comprehensive set of Actions for HUGO in order to build and deploy on GitHub Pages.\nThe workflow consists in having a GitHub Pages repository for the project with a dedicated branch (gh-pages) working as a \u0026ldquo;deployment\u0026rdquo; space for the built assets (i.e. the content of ./public), then configure GitHub Pages to serve the assets on gh-pages rather than main.\nHere\u0026rsquo;s the complete workflow:\nname: GitHub Pages on: push: branches: - main # Set a branch name to trigger deployment pull_request: jobs: deploy: runs-on: ubuntu-20.04 concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.97.2\u0026#39; - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: ${{ github.ref == \u0026#39;refs/heads/main\u0026#39; }} with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public So every push onto main will trigger an Action that will build the site and then push the resulting assets onto gh-pages.\nI\u0026rsquo;m keeping main as a \u0026ldquo;release\u0026rdquo; branch and have dev as the main development branch.\nIn order to create a new blog post then I\u0026rsquo;ll simply\u0026hellip;\nhugo new blog/new-blog-title.md \u0026hellip;and start adding content. Once the post is done, I can quickly check it locally, then merge/push onto main and voil√† üíÅüèª‚Äç‚ôÇÔ∏è üòÉ\nMore info on building and hosting on GitHub:\nHosting HUGO on GitHub Tips And Tricks When building/serving locally, HUGO uses a cache directory ($TMP_DIR/hugo_cache by default). In some cases you might want to ignore the cache and rebuild everything (e.g. changing certain file names might break the build if the cache is not invalidated) so you can pass --ignoreCache to hugo or hugo server commands. Conclusion I think the main strengths of HUGO are its modularity (both in terms of project layout and functionalities) and its community. I also appreciated its good balance between conventions and configurations make it overall extremely flexible yet easy to pick up while using it or, in other terms, very Agile. Also, the complexity doesn\u0026rsquo;t seem to grow dramatically when adding new features and/or diverging from what the theme was initially designed to do.\nSo, I\u0026rsquo;ve had good fun in building this site so far, and I\u0026rsquo;ll definitely keep diving into HUGO.\n","permalink":"https://lucadrf.dev/blog/building-this-site-with-hugo/","tags":["web development","hugo","github"],"title":"Building this site with HUGO"}]